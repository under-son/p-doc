# Other Models

> Configuration examples for various other language models with PraisonAI, including Ollama, FastChat, LM Studio, and Mistral API

```bash
# Ollama
OPENAI_API_BASE='http://localhost:11434/v1'
OPENAI_MODEL_NAME='mistral'
OPENAI_API_KEY='NA'

# FastChat
OPENAI_API_BASE="http://localhost:8001/v1"
OPENAI_MODEL_NAME='oh-2.5m7b-q51'
OPENAI_API_KEY=NA

# LM Studio
OPENAI_API_BASE="http://localhost:1234/v1"
OPENAI_MODEL_NAME=NA
OPENAI_API_KEY=NA

# Mistral API
OPENAI_API_BASE=https://api.mistral.ai/v1
OPENAI_MODEL_NAME="mistral-small"
OPENAI_API_KEY=your-mistral-api-key
```

| PraisonAI Chat                                       | PraisonAI Code                                       | PraisonAI (Multi-Agents) |
| ---------------------------------------------------- | ---------------------------------------------------- | ------------------------ |
| [Litellm](https://litellm.vercel.app/docs/providers) | [Litellm](https://litellm.vercel.app/docs/providers) | [Models](../models.md)   |
